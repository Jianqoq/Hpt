import{_ as n,c as a,d as t,o as e}from"./app-BdPAqzvO.js";const p={};function o(l,s){return e(),a("div",null,s[0]||(s[0]=[t(`<h1>softmax</h1><div class="language-rust line-numbers-mode" data-highlighter="prismjs" data-ext="rs" data-title="rs"><pre><code><span class="line"><span class="token function">softmax</span><span class="token punctuation">(</span></span>
<span class="line">    x<span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token class-name">Tensor</span><span class="token operator">&lt;</span><span class="token class-name">T</span><span class="token operator">&gt;</span><span class="token punctuation">,</span></span>
<span class="line">    dim<span class="token punctuation">:</span> <span class="token keyword">i64</span></span>
<span class="line"><span class="token punctuation">)</span> <span class="token punctuation">-&gt;</span> <span class="token class-name">Result</span><span class="token operator">&lt;</span><span class="token class-name">Tensor</span><span class="token operator">&lt;</span><span class="token class-name">C</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token class-name">TensorError</span><span class="token operator">&gt;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Applies the softmax function to the input tensor along the specified dimension. The softmax function normalizes the input to a probability distribution, such that each element is in the range [0, 1] and all elements sum to 1.</p><h2>Parameters:</h2><p><code>x</code>: Input tensor.</p><p><code>dim</code>: The dimension along which to apply the softmax.</p><h2>Returns:</h2><p>A new tensor with the same shape as input with type <code>C</code></p><h2>Examples:</h2><div class="language-rust line-numbers-mode" data-highlighter="prismjs" data-ext="rs" data-title="rs"><pre><code><span class="line"><span class="token keyword">use</span> <span class="token namespace">hpt<span class="token punctuation">::</span></span><span class="token punctuation">{</span><span class="token namespace">error<span class="token punctuation">::</span></span><span class="token class-name">TensorError</span><span class="token punctuation">,</span> <span class="token namespace">ops<span class="token punctuation">::</span></span><span class="token class-name">NormalizationOps</span><span class="token punctuation">,</span> <span class="token class-name">Tensor</span><span class="token punctuation">}</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">fn</span> <span class="token function-definition function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">-&gt;</span> <span class="token class-name">Result</span><span class="token operator">&lt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">TensorError</span><span class="token operator">&gt;</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token comment">// Create a 2x3 tensor</span></span>
<span class="line">    <span class="token keyword">let</span> x <span class="token operator">=</span> <span class="token class-name">Tensor</span><span class="token punctuation">::</span><span class="token operator">&lt;</span><span class="token keyword">f32</span><span class="token operator">&gt;</span><span class="token punctuation">::</span><span class="token function">new</span><span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">    <span class="token comment">// Apply softmax along dimension 1 (columns)</span></span>
<span class="line">    <span class="token keyword">let</span> result <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token function">softmax</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">?</span><span class="token punctuation">;</span></span>
<span class="line">    <span class="token macro property">println!</span><span class="token punctuation">(</span><span class="token string">&quot;Softmax result:\\n{}&quot;</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token punctuation">;</span></span>
<span class="line"></span>
<span class="line">    <span class="token class-name">Ok</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2>Backend Support</h2><table><thead><tr><th>Backend</th><th>Supported</th></tr></thead><tbody><tr><td>CPU</td><td>✅</td></tr><tr><td>Cuda</td><td>❌</td></tr></tbody></table>`,12)]))}const i=n(p,[["render",o],["__file","softmax.html.vue"]]),u=JSON.parse('{"path":"/user_guide/normalization/softmax.html","title":"softmax","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"Parameters:","slug":"parameters","link":"#parameters","children":[]},{"level":2,"title":"Returns:","slug":"returns","link":"#returns","children":[]},{"level":2,"title":"Examples:","slug":"examples","link":"#examples","children":[]},{"level":2,"title":"Backend Support","slug":"backend-support","link":"#backend-support","children":[]}],"git":{"updatedTime":1741580604000,"contributors":[{"name":"Jianqoq","username":"Jianqoq","email":"ljj1849532909@gmail.com","commits":1,"url":"https://github.com/Jianqoq"}]},"filePathRelative":"user_guide/normalization/softmax.md"}');export{i as comp,u as data};
